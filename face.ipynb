{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc94ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 21:52:17.370929: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-15 21:52:17.601942: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from official.vision.ops import anchor_generator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e86d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 21:52:21.154992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-15 21:52:21.182221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-15 21:52:21.182272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-15 21:52:21.184807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-15 21:52:21.184859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-15 21:52:21.184876: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-15 21:52:21.337740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-15 21:52:21.337865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-15 21:52:21.337877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-07-15 21:52:21.337898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-15 21:52:21.337970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = tfds.load(\n",
    "    'wider_face',\n",
    "    split=['train', 'validation', 'test'],\n",
    "    shuffle_files=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d341c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    img=tf.image.resize(sample['image'],(300,300))\n",
    "    img=img/255.0\n",
    "    box=sample['faces']['bbox']\n",
    "    return img, box\n",
    "\n",
    "train_ds=train_ds.map(preprocess).cache().padded_batch(16,padded_shapes=([300,300,3],[None,4])).shuffle(100).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds=val_ds.map(preprocess).cache().padded_batch(16,padded_shapes=([300,300,3],[None,4]))\n",
    "test_ds=test_ds.map(preprocess).cache().padded_batch(16,padded_shapes=([300,300,3],[None,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c135992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#từ 1 tới 5 theo mô hình vgg16, bỏ phần dưới từ pooling layer ở block 5 đến hết cấu trúc vgg16 gốc\n",
    "#từ 6 đến 11 là phần layer thêm vào theo cấu trúc ssd300\n",
    "input=keras.Input(shape=(300,300,3))\n",
    "#1\n",
    "conv1_1=keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu',padding='same')(input)\n",
    "conv1_2=keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu',padding='same')(conv1_1)\n",
    "pooling1=keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding='same')(conv1_2)\n",
    "#2\n",
    "conv2_1=keras.layers.Conv2D(128,kernel_size=(3,3),activation='relu',padding='same')(pooling1)\n",
    "conv2_2=keras.layers.Conv2D(128,kernel_size=(3,3),activation='relu',padding='same')(conv2_1)\n",
    "pooling2=keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding='same')(conv2_2)\n",
    "#3\n",
    "conv3_1=keras.layers.Conv2D(256,kernel_size=(3,3),activation='relu',padding='same')(pooling2)\n",
    "conv3_2=keras.layers.Conv2D(256,kernel_size=(3,3),activation='relu',padding='same')(conv3_1)\n",
    "conv3_3=keras.layers.Conv2D(256,kernel_size=(3,3),activation='relu',padding='same')(conv3_2)\n",
    "pooling3=keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding='same')(conv3_3)\n",
    "#4\n",
    "conv4_1=keras.layers.Conv2D(512,kernel_size=(3,3),activation='relu',padding='same')(pooling3)\n",
    "conv4_2=keras.layers.Conv2D(512,kernel_size=(3,3),activation='relu',padding='same')(conv4_1)\n",
    "conv4_3=keras.layers.Conv2D(512,kernel_size=(3,3),activation='relu',padding='same')(conv4_2)\n",
    "conv4_3_l2=tf.nn.l2_normalize(conv4_3,axis=-1)#feature map 1 38x38\n",
    "pooling4=keras.layers.MaxPool2D(pool_size=(2,2),strides=1,padding='same')(conv4_3)\n",
    "#5\n",
    "conv5_1=keras.layers.Conv2D(512,kernel_size=(3,3),activation='relu',padding='same')(pooling4)\n",
    "conv5_2=keras.layers.Conv2D(512,kernel_size=(3,3),activation='relu',padding='same')(conv5_1)\n",
    "conv5_3=keras.layers.Conv2D(512,kernel_size=(3,3),activation='relu',padding='same')(conv5_2)\n",
    "#6\n",
    "conv6_1=keras.layers.Conv2D(1024,dilation_rate=6,kernel_size=(3,3),activation='relu',padding='same')(conv5_3)\n",
    "#7\n",
    "conv7_1=keras.layers.Conv2D(1024,kernel_size=(1,1),activation='relu',padding='same')(conv6_1)\n",
    "conv7_2=keras.layers.Conv2D(1024,kernel_size=(3,3),activation='relu',padding='same',strides=2)(conv7_1)#feature map 2 19x19\n",
    "#8\n",
    "conv8_1=keras.layers.Conv2D(256,kernel_size=(1,1),activation='relu',padding='same')(conv7_2)\n",
    "conv8_2=keras.layers.Conv2D(512,kernel_size=(3,3),activation='relu',padding='same',strides=2)(conv8_1)#feature map 3 10x10\n",
    "#9\n",
    "conv9_1=keras.layers.Conv2D(128,kernel_size=(1,1),activation='relu',padding='same')(conv8_2)\n",
    "conv9_2=keras.layers.Conv2D(256,kernel_size=(3,3),activation='relu',padding='same',strides=2)(conv9_1)#feature map 4 5x5\n",
    "#10\n",
    "conv10_1=keras.layers.Conv2D(128,kernel_size=(1,1),activation='relu',padding='same')(conv9_2)\n",
    "conv10_2=keras.layers.Conv2D(256,kernel_size=(3,3),activation='relu',padding='valid',strides=1)(conv10_1)#feature map 5 3x3\n",
    "#11\n",
    "conv11_1=keras.layers.Conv2D(128,kernel_size=(1,1),activation='relu',padding='valid')(conv10_2)\n",
    "conv11_2=keras.layers.Conv2D(256,kernel_size=(3,3),activation='relu',padding='valid',strides=1)(conv11_1)#feature map 6 1x1\n",
    "\n",
    "feature_map=keras.Model(inputs=input,outputs=[conv4_3_l2, conv7_2, conv8_2, conv9_2, conv10_2, conv11_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "009f2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=2\n",
    "n_boxes=4\n",
    "\n",
    "def map_cls_reshape(layer):\n",
    "    map_cls=keras.layers.Conv2D(n_boxes*n_classes,kernel_size=3,padding='same')(layer)\n",
    "    return keras.layers.Reshape((-1,n_classes))(map_cls)\n",
    "\n",
    "def map_box_reshape(layer):\n",
    "    map_box=keras.layers.Conv2D(n_boxes*4,kernel_size=3,padding='same')(layer)\n",
    "    return keras.layers.Reshape((-1,4))(map_box)\n",
    "\n",
    "map1_cls=map_cls_reshape(conv4_3_l2)\n",
    "map1_box=map_box_reshape(conv4_3_l2)\n",
    "\n",
    "map2_cls=map_cls_reshape(conv7_2)\n",
    "map2_box=map_box_reshape(conv7_2)\n",
    "\n",
    "map3_cls=map_cls_reshape(conv8_2)\n",
    "map3_box=map_box_reshape(conv8_2)\n",
    "\n",
    "map4_cls=map_cls_reshape(conv9_2)\n",
    "map4_box=map_box_reshape(conv9_2)\n",
    "\n",
    "map5_cls=map_cls_reshape(conv10_2)\n",
    "map5_box=map_box_reshape(conv10_2)\n",
    "\n",
    "map6_cls=map_cls_reshape(conv11_2)\n",
    "map6_box=map_box_reshape(conv11_2)\n",
    "\n",
    "final_cls_pred=keras.layers.Concatenate(axis=1)([map1_cls, map2_cls, map3_cls, map4_cls, map5_cls, map6_cls])\n",
    "final_box_pred=keras.layers.Concatenate(axis=1)([map1_box, map2_box, map3_box, map4_box, map5_box, map6_box])\n",
    "\n",
    "model=keras.Model(inputs=input,outputs={\n",
    "    'cls':final_cls_pred,\n",
    "    'box':final_box_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c860d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 21:52:27.336831: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-07-15 21:52:27.452843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-07-15 21:52:29.367979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "for sample in train_ds.take(1):\n",
    "    img, box=sample\n",
    "    feature=feature_map(tf.expand_dims(img[0],axis=0))\n",
    "    for i, fmap in enumerate(feature):\n",
    "        smin=0.2\n",
    "        smax=0.9\n",
    "        scl=smin+(smax-smin)*(i)/(6-1)\n",
    "        shape=fmap.shape[1]\n",
    "        anchor=anchor_generator.AnchorGeneratorv1(anchor_sizes=[scl*300],scales=[1],aspect_ratios=[0.5,1.0,2.0],strides=[300/shape],clip_boxes=True)\n",
    "        anchors=anchor((fmap.shape[1],fmap.shape[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
